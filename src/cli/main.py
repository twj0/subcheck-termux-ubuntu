#!/usr/bin/env python3
"""
SubCheck ä¸»å…¥å£ç¨‹åº
ç»Ÿä¸€çš„å‘½ä»¤è¡Œæ¥å£
"""

import sys
import argparse
import asyncio
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.core.config_manager import config
from src.core.subscription_parser import SubscriptionParser
from src.core.optimized_network_tester import OptimizedNetworkTester

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    import logging
    
    log_config = config.get_logging_config()
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_file = Path(log_config['file'])
    log_file.parent.mkdir(parents=True, exist_ok=True)
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=getattr(logging, log_config['level']),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler() if log_config['console'] else logging.NullHandler()
        ]
    )

async def parse_subscriptions(subscription_file: str, output_file: str):
    """è§£æè®¢é˜…"""
    print("ğŸ” è§£æè®¢é˜…æº...")
    
    # è¯»å–è®¢é˜…URLåˆ—è¡¨
    urls = []
    try:
        with open(subscription_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except Exception as e:
        print(f"âŒ è¯»å–è®¢é˜…æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    if not urls:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è®¢é˜…URL")
        return False
    
    print(f"ğŸ“‹ å‘ç° {len(urls)} ä¸ªè®¢é˜…æº")
    
    # è§£æè®¢é˜…
    parser = SubscriptionParser()
    nodes = await parser.parse_multiple_subscriptions(urls)
    
    if not nodes:
        print("âŒ æ²¡æœ‰è§£æåˆ°æœ‰æ•ˆèŠ‚ç‚¹")
        return False
    
    # ä¿å­˜ç»“æœ
    try:
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(nodes, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… è§£æå®Œæˆ: {len(nodes)} ä¸ªèŠ‚ç‚¹å·²ä¿å­˜åˆ° {output_file}")
        return True
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
        return False

async def test_nodes(nodes_file: str, output_file: str, max_nodes: int = None):
    """æµ‹è¯•èŠ‚ç‚¹"""
    print("ğŸš€ å¼€å§‹ç½‘ç»œæµ‹è¯•...")
    
    # è¯»å–èŠ‚ç‚¹æ•°æ®
    try:
        with open(nodes_file, 'r', encoding='utf-8') as f:
            nodes = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–èŠ‚ç‚¹æ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    if not isinstance(nodes, list) or not nodes:
        print("âŒ èŠ‚ç‚¹æ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–ä¸ºç©º")
        return False
    
    # è¿‡æ»¤æœ‰æ•ˆèŠ‚ç‚¹
    valid_nodes = []
    for node in nodes:
        if (node.get('server') and node.get('port') and 
            node.get('type') in ['vless', 'vmess', 'trojan']):
            valid_nodes.append(node)
    
    if not valid_nodes:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
        return False
    
    print(f"ğŸ“Š å‘ç° {len(valid_nodes)} ä¸ªæœ‰æ•ˆèŠ‚ç‚¹")
    
    # é™åˆ¶æµ‹è¯•æ•°é‡
    if max_nodes and len(valid_nodes) > max_nodes:
        valid_nodes = valid_nodes[:max_nodes]
        print(f"ğŸ”¢ é™åˆ¶æµ‹è¯•æ•°é‡ä¸º {max_nodes} ä¸ªèŠ‚ç‚¹")
    
    # å¼€å§‹æµ‹è¯•
    tester = OptimizedNetworkTester()
    
    try:
        await tester.initialize()
        results = await tester.test_multiple_nodes(valid_nodes)
        
        # ä¿å­˜ç»“æœ
        output_path = Path(output_file)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        success_results = [r for r in results if r['status'] == 'success']
        success_count = len(success_results)
        total_count = len(results)
        
        print(f"\nğŸ“ˆ æµ‹è¯•å®Œæˆ:")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {total_count}")
        print(f"   æˆåŠŸèŠ‚ç‚¹: {success_count}")
        print(f"   æˆåŠŸç‡: {success_count/total_count*100:.1f}%")
        print(f"   ç»“æœä¿å­˜: {output_file}")
        
        if success_results:
            # æŒ‰å»¶è¿Ÿæ’åº
            success_results.sort(key=lambda x: x.get('http_latency') or x.get('tcp_latency') or 9999)
            
            print(f"\nğŸ† æœ€ä½³èŠ‚ç‚¹ (å‰5å):")
            for i, result in enumerate(success_results[:5]):
                latency = result.get('http_latency') or result.get('tcp_latency') or 'N/A'
                speed = result.get('download_speed') or 'N/A'
                name = result['name'][:30] if len(result['name']) > 30 else result['name']
                print(f"   {i+1}. {name:<30} {latency:>6}ms {speed:>8}Mbps")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False
    finally:
        await tester.cleanup()

async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='SubCheck - è®¢é˜…èŠ‚ç‚¹æµ‹è¯•å·¥å…·')
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # è§£æå‘½ä»¤
    parse_parser = subparsers.add_parser('parse', help='è§£æè®¢é˜…æº')
    parse_parser.add_argument('subscription_file', help='è®¢é˜…æ–‡ä»¶è·¯å¾„')
    parse_parser.add_argument('-o', '--output', default='data/cache/parsed_nodes.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    # æµ‹è¯•å‘½ä»¤
    test_parser = subparsers.add_parser('test', help='æµ‹è¯•èŠ‚ç‚¹')
    test_parser.add_argument('nodes_file', help='èŠ‚ç‚¹æ–‡ä»¶è·¯å¾„')
    test_parser.add_argument('-o', '--output', default='data/results/test_results.json', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    test_parser.add_argument('-n', '--max-nodes', type=int, help='æœ€å¤§æµ‹è¯•èŠ‚ç‚¹æ•°')
    
    # å®Œæ•´æµç¨‹å‘½ä»¤
    full_parser = subparsers.add_parser('run', help='å®Œæ•´æµç¨‹ï¼šè§£æ+æµ‹è¯•')
    full_parser.add_argument('subscription_file', help='è®¢é˜…æ–‡ä»¶è·¯å¾„')
    full_parser.add_argument('-n', '--max-nodes', type=int, help='æœ€å¤§æµ‹è¯•èŠ‚ç‚¹æ•°')
    full_parser.add_argument('--nodes-output', default='data/cache/parsed_nodes.json', help='èŠ‚ç‚¹è¾“å‡ºæ–‡ä»¶')
    full_parser.add_argument('--results-output', default='data/results/test_results.json', help='ç»“æœè¾“å‡ºæ–‡ä»¶')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    # è®¾ç½®æ—¥å¿—
    setup_logging()
    
    try:
        if args.command == 'parse':
            success = await parse_subscriptions(args.subscription_file, args.output)
            
        elif args.command == 'test':
            success = await test_nodes(args.nodes_file, args.output, args.max_nodes)
            
        elif args.command == 'run':
            # å®Œæ•´æµç¨‹
            print("ğŸ”„ å¼€å§‹å®Œæ•´æµç¨‹...")
            
            # 1. è§£æè®¢é˜…
            if await parse_subscriptions(args.subscription_file, args.nodes_output):
                # 2. æµ‹è¯•èŠ‚ç‚¹
                success = await test_nodes(args.nodes_output, args.results_output, args.max_nodes)
            else:
                success = False
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
